<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>linear_algebra_advance_part_i</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../assets/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": true,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../assets/logo.png" alt="" class="navbar-logo">
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/nodar-okroshiashvili/"><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Okroshiashvili"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/N_Okroshiashvil"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">



<p>Title: Advance Linear Algebra with Python - Part I Date: 2019-03-04 12:14 Category: Mathematics Tags: Linear Algebra, Advance Topics Keywords: eigenvectors and eigenvalues in python, gauss and gauss-jordan elimination with python, matrix image and kernel, advances of linear algebra with python, linear algebra advances with python, numpy, scipy Author: Nodar Okroshiashvili Summary: This is the first part of advance linear algebra with Python</p>
<p>This is the first part of the fourth and last post in blog series about linear algebra.</p>
<ol type="1">
<li>Introduction</li>
<li>Basics of linear algebra</li>
<li>Intermediate linear algebra</li>
<li><strong>Advances in linear algebra</strong>: <strong>Part I</strong> and Part II</li>
</ol>
<p>In this post I will introduce you to the advances of linear algebra, which in turn includes the following:</p>
<ul>
<li><a href="#vector">Vector</a>
<ul>
<li><a href="#basis-vectors">Basis Vectors</a></li>
</ul></li>
<li><a href="#matrix">Matrix</a>
<ul>
<li><a href="#gaussian-elimination-of-a-matrix">Gaussian Elimination of a Matrix</a></li>
<li><a href="#gauss-jordan-elimination-of-a-matrix">Gauss-Jordan Elimination of a Matrix</a></li>
<li><a href="#the-inverse-of-a-matrix-using-gauss-jordan-elimination">The Inverse of a Matrix Using Gauss-Jordan Elimination</a></li>
<li><a href="#image-of-a-matrix">Image of a Matrix</a></li>
<li><a href="#kernel-of-a-matrix">Kernel of a Matrix</a></li>
<li><a href="#rank-of-a-matrix">Rank of a Matrix</a></li>
<li><a href="#find-the-basis-of-a-matrix">Find the Basis of a Matrix</a></li>
<li><a href="#transformations">Transformations</a>
<ul>
<li><a href="#linear-transformation">Linear Transformation</a></li>
<li><a href="#transformations-of-magnitude-and-amplitude">Transformations of Magnitude and Amplitude</a></li>
<li><a href="#affine-transformation">Affine Transformation</a></li>
</ul></li>
<li><a href="#eigenvalues">Eigenvalues</a></li>
<li><a href="#eigenvectors">Eigenvectors</a></li>
<li><a href="#spectrum-and-spectral-radius">Spectrum and Spectral Radius</a></li>
</ul></li>
<li><a href="#numerical-representation">Numerical Representation</a>
<ul>
<li><a href="#kernel-or-null-space-of-a-matrix">Kernel or Null Space of a Matrix</a></li>
<li><a href="#linear-transformations">Linear Transformations</a></li>
<li><a href="#eigenvalues-and-eigenvectors">Eigenvalues and Eigenvectors</a></li>
</ul></li>
<li><a href="#conclusion-for-part-i">Conclusion for part I</a></li>
<li><a href="#references">References</a></li>
</ul>
<section id="vector" class="level2">
<h2 class="anchored" data-anchor-id="vector">Vector</h2>
<section id="basis-vectors" class="level3">
<h3 class="anchored" data-anchor-id="basis-vectors">Basis Vectors</h3>
<p>In the <a href="https://dsfabric.org/articles/mathematics/basics-of-linear-algebra.html">basics</a>, we saw what is a unit vector. To refresh, the unit vector is the vector with length 1 and the formula is</p>
<p><span class="math display">\[
\hat{X} = \frac{X}{\|X\|}
\]</span></p>
<p>For farther explanation, unit vectors can be used to represent the axes of a <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system">Cartesian coordinate system</a>. For example in a three-dimensional Cartesian coordinate system such vectors are:</p>
<p><span class="math display">\[
\hat{i} =
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix}
\quad
\hat{j} =
\begin{bmatrix}
0 \\
1 \\
0
\end{bmatrix}
\quad
\hat{k} =
\begin{bmatrix}
0 \\
0 \\
1
\end{bmatrix}
\]</span></p>
<p>which represents, <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span>, and <span class="math inline">\(z\)</span> axes, respectively.</p>
<p>For two dimensional space we have</p>
<p><span class="math display">\[
\hat{i} =
\begin{bmatrix}
1 \\
0
\end{bmatrix}
\quad
\hat{j} =
\begin{bmatrix}
0 \\
1
\end{bmatrix}
\]</span></p>
<p>Let deal with two-dimensional space to catch the idea of basis easily and then generalize this idea for higher dimensions. Imagine, we have vector space or collection of vectors <span class="math inline">\(\vec{V}\)</span> over the Cartesian coordinate system. This space includes all two-dimensional vectors, or in other words, vectors with only two elements, <span class="math inline">\(x\)</span>, and <span class="math inline">\(y\)</span>.</p>
<blockquote class="blockquote">
<p>A <strong>basis</strong>, call it <span class="math inline">\(B\)</span>, of vector space <span class="math inline">\(V\)</span> over the Cartesian coordinate system is a linearly independent subset of <span class="math inline">\(V\)</span> that spans whole vector space <span class="math inline">\(V\)</span>. To be precise, basis <span class="math inline">\(B\)</span> to be the basis it must satisfy two conditions:</p>
</blockquote>
<ul>
<li><p>Linearly independence property - states that all vectors in <span class="math inline">\(B\)</span> are linearly independent</p></li>
<li><p>The spanning property - states that <span class="math inline">\(B\)</span> spans whole <span class="math inline">\(V\)</span></p></li>
</ul>
<p>We can combine these two conditions in one sentence. <span class="math inline">\(B\)</span> is the basis if its all elements are linearly independent and every element of <span class="math inline">\(V\)</span> is a linear combination of elements of <span class="math inline">\(B\)</span>.</p>
<p>From these conditions, we can conclude that unit vectors <span class="math inline">\(\hat{i}\)</span> and <span class="math inline">\(\hat{j}\)</span> are the basis of <span class="math inline">\(\mathbb{R^2}\)</span>. This kind of bases are also called <strong>standard basis</strong> or <strong>natural basis</strong>. The standard basis are denoted by <span class="math inline">\(e_{1}\)</span>, <span class="math inline">\(e_{2}\)</span>, <span class="math inline">\(e_{3}\)</span> and so on. I will be consistent and use the later notation for standard basis and <span class="math inline">\(\hat{i}\)</span>, <span class="math inline">\(\hat{j}\)</span> and <span class="math inline">\(\hat{k}\)</span> for unit vectors.</p>
<p>These standard basis vectors are the basis in the sense that any other vector in <span class="math inline">\(V\)</span> can be expressed uniquely as a linear combination of these unit vectors. For example, every vector <span class="math inline">\(v\)</span> in two-dimensional space can be written as</p>
<p><span class="math display">\[
x\ e_{1} + y\ e_{2}
\]</span></p>
<p>where <span class="math inline">\(e_{1}\)</span> and <span class="math inline">\(e_{2}\)</span> are unit vectors and <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are scalar components or elements of the vector <span class="math inline">\(v\)</span>.</p>
<p>Now, to generalize the idea for higher dimensions we just have to apply the same logic as above, for <span class="math inline">\(\mathbb{R^3}\)</span> and more. In <span class="math inline">\(\mathbb{R^3}\)</span> we have standard basis vectors <span class="math inline">\(e_{1}\)</span>, <span class="math inline">\(e_{2}\)</span>, <span class="math inline">\(e_{3}\)</span>, and generally for <span class="math inline">\(\mathbb{R^n}\)</span> we have standard basis vector space</p>
<p><span class="math display">\[
E =
\begin{bmatrix}
e_{1} \\
e_{2} \\
\cdots \\
e_{n}
\end{bmatrix}
\]</span></p>
<p>To generalize the definition of basis further let consider the following:</p>
<p><strong>If elements <span class="math inline">\(\{v_{1}, v_{2},\cdots,v_{n}\}\)</span> of <span class="math inline">\(V\)</span> generate <span class="math inline">\(V\)</span> and in addition they are linearly independent, then <span class="math inline">\(\{v_{1}, v_{2},\cdots,v_{n}\}\)</span> is called a basis of <span class="math inline">\(V\)</span>. We shall say that the elements <span class="math inline">\(v_{1}, v_{2},\cdots,v_{n}\)</span> constitute or form a basis of V.</strong> Vector space <span class="math inline">\(V\)</span> can have several basis.</p>
<p>At this stage, the notion of basis seems very abstract even for me, and believe me it was totally unclear for me until I solved some examples by hand. I’ll show you how to compute basis after explaining row-echelon and reduced row-echelon forms and you’ll understand it. However, it’s not enough only to know how to row-reduce the given matrix. It’s necessary to know which basis you want. Either column space or row space basis or the basis for nullspace. These notions are explained below and after that, we can find the basis for each of them.</p>
</section>
</section>
<section id="matrix" class="level2">
<h2 class="anchored" data-anchor-id="matrix">Matrix</h2>
<section id="gaussian-elimination-of-a-matrix" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-elimination-of-a-matrix">Gaussian Elimination of a Matrix</h3>
<p>In linear algebra, Gaussian Elimination is the method to solve the system of linear equations. This method is the sequence of operations performed on the coefficient matrix of the system. Except for solving the linear systems, the method can be used to find the rank of a matrix, the determinant as well as the inverse of a square invertible matrix.</p>
<p>And what is the sequence of operations?</p>
<p>Under this notion, elementary row operations are meant. We’ve covered it in the previous post but for the refresher, ERO’s are:</p>
<ul>
<li><p>Interchange rows</p></li>
<li><p>Multiply each element in a row by a non-zero number</p></li>
<li><p>Multiply a row by a non-zero number and add the result to another row</p></li>
</ul>
<p>Performing Gaussian elimination results in the matrix in <strong>Row Echelon Form</strong> (ref). The matrix is said to be in row echelon form if it satisfies the following conditions:</p>
<ul>
<li><p>The first non-zero element in each row, called the leading entry, is a 1</p></li>
<li><p>Each leading entry is in a column, which is the right side of the leading entry in the previous row</p></li>
<li><p>Below the leading entry in a column, all other entries are zero</p></li>
</ul>
<p>To catch the idea of this process, let consider the example. Actually, we have no matrix (not necessarily true), we have the system of linear equations in the following form:</p>
<p><span class="math display">\[
\begin{cases}
x + 2y - z = 5\\
3x + y - 2z = 9\\
-x + 4y + 2z = 0
\end{cases}
\]</span></p>
<p>Based on these equations we can form the following matrix</p>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 \\
3 &amp; 1 &amp; -2 \\
-1 &amp; 4 &amp; 2
\end{bmatrix}
\]</span></p>
<p>This matrix is called <strong>coefficient matrix</strong> as it contains the coefficients of the linear equations. Having the coefficient matrix, we can rewrite our system in the following form:</p>
<p><span class="math display">\[
Ax = b
\]</span></p>
<p>Where <span class="math inline">\(A\)</span> is the coefficient matrix, <span class="math inline">\(x\)</span> is the vector of the unknowns, and <span class="math inline">\(b\)</span> is the vector of the right-hand side components</p>
<p>To solve this simultaneous system, the coefficients matrix is not enough. We need something more, on which we can perform ELO’s. This matrix is:</p>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
3 &amp; 1 &amp; -2 &amp; |&amp; 9 \\
-1 &amp; 4 &amp; 2 &amp; |&amp; 0
\end{bmatrix} = [A | b]
\]</span></p>
<p>which is called <strong>augmented matrix</strong>, which in turn gives us the possibility to perform ELO’s, in other words, we do Gaussian elimination and the resulted matrix will be in row echelon form. Using back substitution on the resulted matrix gives the solution to our system of equations.</p>
<p>Let do it by hand. We have the initial system</p>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
3 &amp; 1 &amp; -2 &amp; |&amp; 9 \\
-1 &amp; 4 &amp; 2 &amp; |&amp; 0
\end{bmatrix}
\equiv
\begin{cases}
x + 2y - z = 5 \\
3x + y - 2z = 9 \\
-x + 4y + 2z = 0
\end{cases}
\]</span></p>
<p>Then, using ERO’s</p>
<ol type="1">
<li><span class="math inline">\(R3 \rightarrow R3 + R1\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
3 &amp; 1 &amp; -2 &amp; |&amp; 9 \\
0 &amp; 6 &amp; 1 &amp; |&amp; 5
\end{bmatrix}
\equiv
\begin{cases}
x + 2y - z = 5 \\
3x + y - 2z = 9 \\
6y + z = 5
\end{cases}
\]</span></p>
<ol start="2" type="1">
<li><span class="math inline">\(R2 \rightarrow R2 - 3R1\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
0 &amp; -5 &amp; 1 &amp; |&amp; -6 \\
0 &amp; 6 &amp; 1 &amp; |&amp; 5
\end{bmatrix}
\equiv
\begin{cases}
x + 2y - z = 5 \\
-5y + z = -6 \\
6y + z = 5
\end{cases}
\]</span></p>
<ol start="3" type="1">
<li><span class="math inline">\(R2 \rightarrow R2 + R3\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
0 &amp; 1 &amp; 2 &amp; |&amp; -1 \\
0 &amp; 6 &amp; 1 &amp; |&amp; 5
\end{bmatrix}
\equiv
\begin{cases}
x + 2y - z = 5 \\
y + 2z = -1 \\
6y + z = 5
\end{cases}
\]</span></p>
<ol start="4" type="1">
<li><span class="math inline">\(R3 \rightarrow R3 - 6R2\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
0 &amp; 1 &amp; 2 &amp; |&amp; -1 \\
0 &amp; 0 &amp; -11 &amp; |&amp; 11
\end{bmatrix}
\equiv
\begin{cases}
x + 2y - z = 5 \\
y + 2z = -1 \\
-11z = 11
\end{cases}
\]</span></p>
<ol start="5" type="1">
<li><span class="math inline">\(R3 \rightarrow R3 \cdot -\frac{1}{11}\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
0 &amp; 1 &amp; 2 &amp; |&amp; -1 \\
0 &amp; 0 &amp; 1 &amp; |&amp; -1
\end{bmatrix}
\equiv
\begin{cases}
x + 2y - z = 5 \quad (A)\\
y + 2z = -1 \quad (B)\\
z = -1 \quad (C)
\end{cases}
\]</span></p>
<ol start="6" type="1">
<li>Back substitution</li>
</ol>
<p><span class="math display">\[
\begin{cases}
(C) \quad z = -1 \\
(B) \quad y = -1 - 2z \quad \Rightarrow \quad y = -1 - 2(-1) = 1 \\
(A) \quad x = 5 - 2y + z \quad \Rightarrow \quad x = 5 - 2(1) + (-1) = 2
\end{cases}
\]</span></p>
<ol start="7" type="1">
<li>Solution</li>
</ol>
<p><span class="math display">\[
x = 2 \\
y = 1 \\
x = -1
\]</span></p>
<p>This is the solution of the initial system, as well as the last system and every intermediate system. The matrix obtained in step 5 above is in Row-Echelon form as it satisfied above-mentioned conditions.</p>
<p><strong>Note that, starting with a particular matrix, a different sequence of ERO’s can lead to different row echelon form</strong></p>
</section>
<section id="gauss-jordan-elimination-of-a-matrix" class="level3">
<h3 class="anchored" data-anchor-id="gauss-jordan-elimination-of-a-matrix">Gauss-Jordan Elimination of a Matrix</h3>
<p>Gaussian elimination performs row operations to produce zeros below the main diagonal of the coefficient matrix to reduce it to row echelon form. Once it’s done we perform back substitution to find the solution. However, we can continue performing ERO’s to reduce coefficient matrix farther, to produce <strong>Reduced Row Echelon Form</strong> (rref). The matrix is in reduced row echelon form if it satisfies the following conditions:</p>
<ul>
<li><p>It is in row echelon form</p></li>
<li><p>The leading entry in each row is the only non-zero entry in its column</p></li>
</ul>
<p>Gauss-Jordan elimination starts when Gauss elimination left off. Loosely speaking, Gaussian elimination works from the top down and when it stops, we start Gauss-Jordan elimination from the bottom up. The Reduced Row Echelon Form matrix is the result of Gauss-Jordan Elimination process.</p>
<p>We can continue our example from step 5 and see what is Gauss-Jordan elimination. At step 5 we had</p>
<ol type="1">
<li><span class="math inline">\(R3 \rightarrow R3 \cdot -\frac{1}{11}\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
0 &amp; 1 &amp; 2 &amp; |&amp; -1 \\
0 &amp; 0 &amp; 1 &amp; |&amp; -1
\end{bmatrix}
\equiv
\begin{cases}
x + 2y - z = 5 \\
y + 2z = -1 \\
z = -1
\end{cases}
\]</span></p>
<p>Now, from bottom to up we perform the following ERO’s</p>
<ol start="6" type="1">
<li><span class="math inline">\(R2 \rightarrow R2 - 2R3\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 5 \\
0 &amp; 1 &amp; 0 &amp; |&amp; 1 \\
0 &amp; 0 &amp; 1 &amp; |&amp; -1
\end{bmatrix}
\equiv
\begin{cases}
x + 2y - z = 5 \\
y  = 1 \\
z = -1
\end{cases}
\]</span></p>
<ol start="7" type="1">
<li><span class="math inline">\(R1 \rightarrow R1 + R3\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; |&amp; 4 \\
0 &amp; 1 &amp; 0 &amp; |&amp; 1 \\
0 &amp; 0 &amp; 1 &amp; |&amp; -1
\end{bmatrix}
\equiv
\begin{cases}
x + 2y = 4 \\
y  = 1 \\
z = -1
\end{cases}
\]</span></p>
<ol start="8" type="1">
<li><span class="math inline">\(R1 \rightarrow R1 - 2R2\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; |&amp; 2 \\
0 &amp; 1 &amp; 0 &amp; |&amp; 1 \\
0 &amp; 0 &amp; 1 &amp; |&amp; -1
\end{bmatrix}
\equiv
\begin{cases}
x = 2 \\
y = 1 \\
z = -1
\end{cases}
\]</span></p>
<p>The solution is</p>
<p><span class="math display">\[
x = 2 \\
y = 1 \\
x = -1
\]</span></p>
<p>and this is the same as the solution of the Gauss elimination. The matrix in step 8 is the Reduced Row Echelon Form of our initial coefficient matrix <span class="math inline">\(A\)</span>.</p>
</section>
<section id="the-inverse-of-a-matrix-using-gauss-jordan-elimination" class="level3">
<h3 class="anchored" data-anchor-id="the-inverse-of-a-matrix-using-gauss-jordan-elimination">The Inverse of a Matrix Using Gauss-Jordan Elimination</h3>
<p>Suppose, we have given the matrix and want to find its inverse but do not want to use the technique mentioned in the intermediate post. We can use Gauss-Jordan elimination with little modification to find the inverse of a matrix. To be consistent, I use the above coefficient matrix but not the right-hand side of the system. So, our matrix is</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
1 &amp; 2 &amp; -1 \\
3 &amp; 1 &amp; -2 \\
-1 &amp; 4 &amp; 2
\end{bmatrix}
\]</span></p>
<p>To find the inverse of <span class="math inline">\(A\)</span>, we need to augment <span class="math inline">\(A\)</span> by the identity matrix <span class="math inline">\(I\)</span> which has the same dimensions as <span class="math inline">\(A\)</span>. It is a must the identity to have the same dimensions. After augmentation we have</p>
<p><span class="math display">\[
[A | I] =
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 1 &amp; 0 &amp; 0 \\
3 &amp; 1 &amp; -2 &amp; |&amp; 0 &amp; 1 &amp; 0 \\
-1 &amp; 4 &amp; 2 &amp; |&amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<p>We have to perform elementary row operations in the same way as we did in the above example. Particularly,</p>
<ol type="1">
<li><span class="math inline">\(R3 \rightarrow R3 + R1\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 1 &amp; 0 &amp; 0\\
3 &amp; 1 &amp; -2 &amp; |&amp; 0 &amp; 1 &amp; 0\\
0 &amp; 6 &amp; 1 &amp; |&amp; 1 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<ol start="2" type="1">
<li><span class="math inline">\(R2 \rightarrow R2 - 3R1\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 1 &amp; 0 &amp; 0\\
0 &amp; -5 &amp; 1 &amp; |&amp; -3 &amp; 1 &amp; -3\\
0 &amp; 6 &amp; 1 &amp; |&amp; 1 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<ol start="3" type="1">
<li><span class="math inline">\(R2 \rightarrow R2 + R3\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 2 &amp; |&amp; -2 &amp; 1 &amp; -2\\
0 &amp; 6 &amp; 1 &amp; |&amp; 1 &amp; 0 &amp; 1
\end{bmatrix}
\]</span></p>
<ol start="4" type="1">
<li><span class="math inline">\(R3 \rightarrow R3 - 6R2\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 2 &amp; |&amp; -2 &amp; 1 &amp; -2\\
0 &amp; 0 &amp; -11 &amp; |&amp; 13 &amp; -6 &amp; 13
\end{bmatrix}
\]</span></p>
<ol start="5" type="1">
<li><span class="math inline">\(R3 \rightarrow R3 \cdot -\frac{1}{11}\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 2 &amp; |&amp; -2 &amp; 1 &amp; -2\\
0 &amp; 0 &amp; 1 &amp; |&amp; -\frac{13}{11} &amp; \frac{6}{11} &amp; -\frac{13}{11}
\end{bmatrix}
\]</span></p>
<ol start="6" type="1">
<li><span class="math inline">\(R2 \rightarrow R2 - 2R3\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; -1 &amp; |&amp; 1 &amp; 0 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; |&amp; \frac{4}{11} &amp; -\frac{9}{100} &amp; \frac{4}{11}\\
0 &amp; 0 &amp; 1 &amp; |&amp; -\frac{13}{11} &amp; \frac{6}{11} &amp; -\frac{13}{11}
\end{bmatrix}
\]</span></p>
<ol start="7" type="1">
<li><span class="math inline">\(R1 \rightarrow R1 + R3\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; |&amp; -\frac{2}{11} &amp; \frac{6}{11} &amp; -\frac{13}{11}\\
0 &amp; 1 &amp; 0 &amp; |&amp; \frac{4}{11} &amp; -\frac{9}{100} &amp; \frac{4}{11}\\
0 &amp; 0 &amp; 1 &amp; |&amp; -\frac{13}{11} &amp; \frac{6}{11} &amp; -\frac{13}{11}
\end{bmatrix}
\]</span></p>
<ol start="8" type="1">
<li><span class="math inline">\(R1 \rightarrow R1 - 2R2\)</span></li>
</ol>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; |&amp; -\frac{10}{11} &amp; \frac{18}{25} &amp; -\frac{21}{11}\\
0 &amp; 1 &amp; 0 &amp; |&amp; \frac{4}{11} &amp; -\frac{9}{100} &amp; \frac{4}{11}\\
0 &amp; 0 &amp; 1 &amp; |&amp; -\frac{13}{11} &amp; \frac{6}{11} &amp; -\frac{13}{11}
\end{bmatrix}
\]</span></p>
<p>Our inverse of <span class="math inline">\(A\)</span> is</p>
<p><span class="math display">\[
A^{-1} =
\begin{bmatrix}
-\frac{10}{11} &amp; \frac{18}{25} &amp; -\frac{21}{11}\\
\frac{4}{11} &amp; -\frac{9}{100} &amp; \frac{4}{11}\\
-\frac{13}{11} &amp; \frac{6}{11} &amp; -\frac{13}{11}
\end{bmatrix}
\]</span></p>
</section>
<section id="image-of-a-matrix" class="level3">
<h3 class="anchored" data-anchor-id="image-of-a-matrix">Image of a Matrix</h3>
<p>Let <span class="math inline">\(A\)</span> be <span class="math inline">\(m\times n\)</span> matrix. Space spanned by its column vectors are called range, image, or column space of a matrix <span class="math inline">\(A\)</span>. The row space is defined similarly. I only consider column space as all the logic is the same for row space.</p>
<p>The precise definition is the following:</p>
<p>Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(m\times n\)</span> matrix, with column vectors <span class="math inline">\(v_{1}, v_{2}, \cdots, v_{n}\)</span>. A linear combination of these vectors is any vector of the following form: <span class="math inline">\(c_{1}v_{1} + c_{2}v_{2} + \cdots + c_{n}v_{n}\)</span>, where <span class="math inline">\(c_{1}, c_{2}, \cdots , c_{n}\)</span> are scalars. The set of all possible linear combinations of <span class="math inline">\(v_{1}, v_{2}, \cdots , v_{n}\)</span> is called the column space of <span class="math inline">\(A\)</span>.</p>
<p>For example:</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
1 &amp; 0\\
0 &amp; 1\\
2 &amp; 0
\end{bmatrix}
\]</span></p>
<p>Column vectors are:</p>
<p><span class="math display">\[
v_{1} =
\begin{bmatrix}
1\\
0\\
2
\end{bmatrix}
\quad
v_{2} =
\begin{bmatrix}
0\\
1\\
0
\end{bmatrix}
\]</span></p>
<p>A linear combination of <span class="math inline">\(v_{1}\)</span> and <span class="math inline">\(v_{2}\)</span> is any vector of the form</p>
<p><span class="math display">\[
c_{1}
\begin{bmatrix}
1\\
0\\
2
\end{bmatrix} + c_{2}
\begin{bmatrix}
0\\
1\\
0
\end{bmatrix} =
\begin{bmatrix}
c_{1}\\
c_{2}\\
2c_{1}
\end{bmatrix}
\]</span></p>
<p>The set of all such vectors is the column space of <span class="math inline">\(A\)</span>.</p>
</section>
<section id="kernel-of-a-matrix" class="level3">
<h3 class="anchored" data-anchor-id="kernel-of-a-matrix">Kernel of a Matrix</h3>
<p>In linear algebra, the kernel or a.k.a null space is the solution of the following homogeneous system:</p>
<p><span class="math display">\[A\cdot X = 0\]</span></p>
<p>where <span class="math inline">\(A\)</span> is a <span class="math inline">\(m\times n\)</span> matrix and <span class="math inline">\(X\)</span> is a <span class="math inline">\(m\times 1\)</span> vector and is denoted by <span class="math inline">\(Ker(A)\)</span>.</p>
<p>For more clarity, let consider the numerical example. Lat our matrix <span class="math inline">\(A\)</span> be the following:</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 7 &amp; 1 &amp; 3 \\
-4 &amp; -2 &amp; 2 &amp; -2 \\
-1 &amp; 7 &amp; 3 &amp; 2 \\
-2 &amp; 2 &amp; 2 &amp; 0 \\
\end{bmatrix}
\]</span></p>
<p>and our <span class="math inline">\(X\)</span> is</p>
<p><span class="math display">\[
X =
\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4} \\
\end{bmatrix}
\]</span></p>
<p>We have to form the following system:</p>
<p><span class="math display">\[
A\cdot X =
\begin{bmatrix}
2 &amp; 7 &amp; 1 &amp; 3 \\
-4 &amp; -2 &amp; 2 &amp; -2 \\
-1 &amp; 7 &amp; 3 &amp; 2 \\
-2 &amp; 2 &amp; 2 &amp; 0 \\
\end{bmatrix}
\cdot
\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4} \\
\end{bmatrix} =
\begin{bmatrix}
0 \\
0 \\
0 \\
0 \\
\end{bmatrix}
\]</span></p>
<p>After that, we have to put this system into row-echelon or reduced row-echelon form. Let skip detailed calculation and present only results, which is the last matrix.</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 7 &amp; 1 &amp; 3\\
-4 &amp; -2 &amp; 2 &amp; -2\\
-1 &amp; 7 &amp; 3 &amp; 2\\
-2 &amp; 2 &amp; 2 &amp; 0
\end{bmatrix}
\rightarrow
\begin{bmatrix}
-1 &amp; 7 &amp; 3 &amp; 2\\
-4 &amp; -2 &amp; 2 &amp; -2\\
2 &amp; 7 &amp; 1 &amp; 3\\
-2 &amp; 2 &amp; 2 &amp; 0
\end{bmatrix}
\rightarrow
\begin{bmatrix}
-1 &amp; 7 &amp; 3 &amp; 2\\
0 &amp; -30 &amp; -10 &amp; -10\\
0 &amp; 21 &amp; 7 &amp; 7\\
0 &amp; -12 &amp; -4 &amp; -4
\end{bmatrix}
\rightarrow
\begin{bmatrix}
-1 &amp; 7 &amp; 3 &amp; 2\\
0 &amp; 3 &amp; 1 &amp; 1\\
0 &amp; 3 &amp; 1 &amp; 1\\
0 &amp; 3 &amp; 1 &amp; 1
\end{bmatrix}
\rightarrow
\begin{bmatrix}
-1 &amp; 7 &amp; 3 &amp; 2\\
0 &amp; 3 &amp; 1 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span></p>
<p>Now, to find the kernel of the original matrix <span class="math inline">\(A\)</span>, we have to solve the following system of equations:</p>
<p><span class="math display">\[
\begin{cases}
x_{1} - 7x_{2} - 3x_{3} - 2x_{4} = 0 \\
        3x_{2} + x_{3} + x_{4} = 0
\end{cases}
\rightarrow
\begin{cases}
x_{1} = \frac{2}{3}x_{3} - \frac{1}{3}x_{4}\\
x_{2} = -\frac{1}{3}x_{3} - \frac{1}{3}x_{4}
\end{cases}
\]</span></p>
<p>From this solution we conclude that the kernel of <span class="math inline">\(A\)</span> is</p>
<p><span class="math display">\[
Ker(A) =
\begin{bmatrix}
x_{1} = \frac{2}{3}x_{3} - \frac{1}{3}x_{4} \\
x_{2} = -\frac{1}{3}x_{3} - \frac{1}{3}x_{4} \\
x_{3} \\
x_{4}
\end{bmatrix}
\]</span></p>
<p>Where, <span class="math inline">\(x_{3}\)</span> and <span class="math inline">\(x_{4}\)</span> are free variables and can be any number in <span class="math inline">\(R\)</span></p>
<p>Note, that both original matrix <span class="math inline">\(A\)</span> and its row-echelon for has the same kernel. This means that row reduction preserves the kernel or null space.</p>
</section>
<section id="rank-of-a-matrix" class="level3">
<h3 class="anchored" data-anchor-id="rank-of-a-matrix">Rank of a Matrix</h3>
<p>In the intermediate tutorial, you saw how to calculate the determinant of a matrix and also saw that any non zero determinant of sub-matrix of the original matrix shows its non-degenerateness. In other words, nonzero determinant gives us information about the rank of the matrix. Also, I said that there was not only one way to find the rank of a matrix. After reviewing Gauss and Gauss-Jordan Elimination and Row-Echelon and Reduced Row-Echelon forms you know that indeed there are other ways to find the determinant of a matrix as well as the rank of the matrix. To keep <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY</a>, here I only consider a numerical example. The code is provided in the intermediate tutorial.</p>
<p>Suppose we have matrix <span class="math inline">\(A\)</span> in the following form:</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
3 &amp; 2 &amp; -1\\
2 &amp; -3 &amp; -5\\
-1 &amp; -4 &amp;- 3
\end{bmatrix}
\]</span></p>
<p>Perform Elementary Row Operations we get reduced-echelon form:</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
3 &amp; 2 &amp; -1\\
2 &amp; -3 &amp; -5\\
-1 &amp; -4 &amp; -3
\end{bmatrix}
\rightarrow
\begin{bmatrix}
1 &amp; 4 &amp; 3\\
3 &amp; 2 &amp; -1\\
2 &amp; -3 &amp; -5
\end{bmatrix}
\rightarrow
\begin{bmatrix}
1 &amp; 4 &amp; 3\\
0 &amp; -10 &amp; -10\\
0 &amp; -11 &amp; -11
\end{bmatrix}
\rightarrow
\begin{bmatrix}
1 &amp; 4 &amp; 3\\
0 &amp; 1 &amp; 1\\
0 &amp; -11 &amp; -11
\end{bmatrix}
\rightarrow
\begin{bmatrix}
1 &amp; 4 &amp; 3\\
0 &amp; 1 &amp; 1\\
0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span></p>
<p>From the last matrix we see that the nonzero determinant only exists in <span class="math inline">\(2\times2\)</span> sub-matrices, hence rank of the matrix <span class="math inline">\(A\)</span> is 2.</p>
</section>
<section id="find-the-basis-of-a-matrix" class="level3">
<h3 class="anchored" data-anchor-id="find-the-basis-of-a-matrix">Find the Basis of a Matrix</h3>
<p>Now we are able to find the basis for column space and row space as well as the basis for the kernel. The columns of a matrix <span class="math inline">\(A\)</span> span the column space but they may not form a basis if the column vectors are linearly dependent. If this is the case, only some subset of these vectors forms the basis. To find the basis for column space we reduce matrix <span class="math inline">\(A\)</span> to reduced row-echelon form.</p>
<p>For example:</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 7 &amp; 1 &amp; 3 \\
-4 &amp; -2 &amp; 2 &amp; -2 \\
-1 &amp; 7 &amp; 3 &amp; 2 \\
-2 &amp; 2 &amp; 2 &amp; 0 \\
\end{bmatrix}
\]</span></p>
<p>Row reduced form of <span class="math inline">\(A\)</span> is:</p>
<p><span class="math display">\[
B =
\begin{bmatrix}
-1 &amp; 7 &amp; 3 &amp; 2\\
0 &amp; 3 &amp; 1 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span></p>
<p>We see that only column 1 and column 2 are linearly independent in reduced form and hence column 1 and column 2 of the original matrix <span class="math inline">\(A\)</span> form the basis, which is:</p>
<p><span class="math display">\[
\begin{bmatrix}
2 \\-4\\-1\\-2
\end{bmatrix}
\quad
\text{and}
\quad
\begin{bmatrix}
7\\-2 \\ 7 \\ 2
\end{bmatrix}
\]</span></p>
<p>To find the basis for row space, let consider different matrix and again let it be <span class="math inline">\(A\)</span>.</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
1 &amp; 3 &amp; 2 \\
2 &amp; 7 &amp; 4 \\
1 &amp; 5 &amp; 2
\end{bmatrix}
\]</span></p>
<p>To reduce <span class="math inline">\(A\)</span> to reduced row-echelon form we have:</p>
<p><span class="math display">\[
B =
\begin{bmatrix}
1 &amp; 0 &amp; 2 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span></p>
<p>As in column space case, we see that linearly independent, nonzero row vectors are</p>
<p><span class="math display">\[
\begin{bmatrix}
1 \\0\\2
\end{bmatrix}
\quad
\text{and}
\quad
\begin{bmatrix}
0\\1 \\ 0
\end{bmatrix}
\]</span></p>
<p>To find the basis for kernel let consider our old example. In this case our matrix is:</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 7 &amp; 1 &amp; 3 \\
-4 &amp; -2 &amp; 2 &amp; -2 \\
-1 &amp; 7 &amp; 3 &amp; 2 \\
-2 &amp; 2 &amp; 2 &amp; 0 \\
\end{bmatrix}
\]</span></p>
<p>And its row reduced form is</p>
<p><span class="math display">\[
B =
\begin{bmatrix}
-1 &amp; 7 &amp; 3 &amp; 2\\
0 &amp; 3 &amp; 1 &amp; 1\\
0 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}
\]</span></p>
<p>We solved this and got the following result:</p>
<p><span class="math display">\[
Ker(A) =
\begin{bmatrix}
x_{1} = \frac{2}{3}x_{3} - \frac{1}{3}x_{4} \\
x_{2} = -\frac{1}{3}x_{3} - \frac{1}{3}x_{4} \\
x_{3} \\
x_{4}
\end{bmatrix}
\]</span></p>
<p>Now to have basis for null space just plug values for <span class="math inline">\(x_{3} = 1\)</span> and <span class="math inline">\(x_{4} = 0\)</span>, resulted vector is</p>
<p><span class="math display">\[
\begin{bmatrix}
\frac{2}{3} \\
-\frac{1}{3} \\
1 \\
0
\end{bmatrix}
\]</span></p>
<p>The resulted vector is one set of the basis for kernel space. The values for <span class="math inline">\(x_{3}\)</span> and <span class="math inline">\(x_{4}\)</span> are up to you as they are free variables.</p>
</section>
<section id="transformations" class="level3">
<h3 class="anchored" data-anchor-id="transformations">Transformations</h3>
<p>Matrices and vectors are used together to manipulate spatial dimensions. This has a lot of applications, including the mathematical generation of 3D computer graphics, geometric modeling, and the training and optimization of machine learning algorithms. Here, I present some types of transformation. However, the list will not be exhaustive. Firstly, define linear transformation:</p>
<blockquote class="blockquote">
<p>Linear transformation or linear map, is a mapping (function) between two vector spaces that preserves addition and scalar multiplication operations</p>
</blockquote>
<section id="linear-transformation" class="level4">
<h4 class="anchored" data-anchor-id="linear-transformation">Linear Transformation</h4>
<p>You can manipulate a vector by multiplying it with a matrix. The matrix acts like a function that operates on an input vector to produce a vector output. Specifically, matrix multiplications of vectors are <em>linear transformations</em> that transform the input vector into the output vector.</p>
<p>For example, consider a matrix <span class="math inline">\(A\)</span> and vector <span class="math inline">\(v\)</span></p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; 2
\end{bmatrix}
\quad
\vec{v} =
\begin{bmatrix}
1 \\
2
\end{bmatrix}
\]</span></p>
<p>Define transformation <span class="math inline">\(T\)</span> to be:</p>
<p><span class="math display">\[
T(\vec{v}) = A \vec{v}
\]</span></p>
<p>This transformation is simply dot or inner product and give the following result:</p>
<p><span class="math display">\[
T(\vec{v}) = A \vec{v} =
\begin{bmatrix}
8 \\
9
\end{bmatrix}
\]</span></p>
<p>In this case, both the input and output vector has 2 components. In other words, the transformation takes a 2-dimensional vector and produces a new 2-dimensional vector. Formally we can write this in the following way:</p>
<p><span class="math display">\[
T: \rm I\!R^{2} \to \rm I\!R^{2}
\]</span></p>
<p>The transformation does not necessarily have to be <span class="math inline">\(n \times n\)</span>. The dimension of the output vector and the input vector may differ. Rewrite our matrix <span class="math inline">\(A\)</span> and vector <span class="math inline">\(v\)</span>.</p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 3 \\
5 &amp; 2 \\
1 &amp; 1
\end{bmatrix}
\quad
\vec{v} =
\begin{bmatrix}
1 \\
2
\end{bmatrix}
\]</span></p>
<p>Apply above transformation gives,</p>
<p><span class="math display">\[
T(\vec{v}) = A \vec{v} =
\begin{bmatrix}
8 \\
9 \\
3
\end{bmatrix}
\]</span></p>
<p>Now, our transformation transforms a vector from 2-dimensional space into 3-dimensional space. We can rite this transformation as</p>
<p><span class="math display">\[
T: \rm I\!R^{2} \to \rm I\!R^{3}
\]</span></p>
</section>
<section id="transformations-of-magnitude-and-amplitude" class="level4">
<h4 class="anchored" data-anchor-id="transformations-of-magnitude-and-amplitude">Transformations of Magnitude and Amplitude</h4>
<p>When we multiply a vector by a matrix we transform it in at least one of the following two ways</p>
<ul>
<li><p>Scale the length (Magnitude)</p></li>
<li><p>Change the direction (Amplitude)</p></li>
</ul>
<p><em>Change in length (Magnitude), but not change in direction (Amplitude)</em></p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 0 \\
0 &amp; 2
\end{bmatrix}
\quad
\vec{v} =
\begin{bmatrix}
1 \\
0
\end{bmatrix}
\]</span></p>
<p>transformation gives,</p>
<p><span class="math display">\[
T(\vec{v}) = A \vec{v} =
\begin{bmatrix}
2 \\
0
\end{bmatrix}
\]</span></p>
<p>In this case, the resulted vector changed in length but not changed in direction. See code and visualization in Numerical Representation part.</p>
<p><em>Change in direction (Amplitude), but not change in length (Magnitude)</em></p>
<p><span class="math display">\[
A =
\begin{bmatrix}
0 &amp; -1 \\
1 &amp; 0
\end{bmatrix}
\quad
\vec{v} =
\begin{bmatrix}
1 \\
0
\end{bmatrix}
\]</span></p>
<p>transformation gives,</p>
<p><span class="math display">\[
T(\vec{v}) = A \vec{v} =
\begin{bmatrix}
0 \\
1
\end{bmatrix}
\]</span></p>
<p>This time, resulted vector changed in direction but has the same length.</p>
<p><em>Change in direction (Amplitude) and in length (Magnitude)</em></p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 1 \\
1 &amp; 2
\end{bmatrix}
\quad
\vec{v} =
\begin{bmatrix}
1 \\
0
\end{bmatrix}
\]</span></p>
<p>transformation gives,</p>
<p><span class="math display">\[
T(\vec{v}) = A \vec{v} =
\begin{bmatrix}
2 \\
1
\end{bmatrix}
\]</span></p>
<p>This time the resulted vector changed in the direction as well as the length.</p>
</section>
<section id="affine-transformation" class="level4">
<h4 class="anchored" data-anchor-id="affine-transformation">Affine Transformation</h4>
<p>An Affine transformation multiplies a vector by a matrix and adds an offset vector, sometimes referred to as <em>bias</em>.</p>
<p><span class="math display">\[
T(\vec{v}) = A\vec{v} + \vec{b}
\]</span></p>
<p>Consider following example</p>
<p><span class="math display">\[
T(\vec{v}) = A\vec{v} + \vec{b} =
\begin{bmatrix}
5 &amp; 2\\
3 &amp; 1
\end{bmatrix} \cdot
\begin{bmatrix}
1\\
1
\end{bmatrix} +
\begin{bmatrix}
-2\\
-6
\end{bmatrix} =
\begin{bmatrix}
5\\
-2
\end{bmatrix}
\]</span></p>
<p>This kind of transformation is actually the basic block of linear regression, which is a core foundation for machine learning. However, these concepts are out of the scope of this tutorial. Python code is below for this transformation.</p>
</section>
</section>
<section id="eigenvalues" class="level3">
<h3 class="anchored" data-anchor-id="eigenvalues">Eigenvalues</h3>
<p>Let consider matrix <span class="math inline">\(A\)</span></p>
<p><span class="math display">\[
A =
\begin{bmatrix}
2 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 4 \\
0 &amp; 4 &amp; 9
\end{bmatrix}
\]</span></p>
<p>Now, let multiply this matrix with vector <span class="math display">\[
\vec{v} =
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix}
\]</span></p>
<p>We have the following:</p>
<p><span class="math display">\[
A \cdot v =
\begin{bmatrix}
2 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 4 \\
0 &amp; 4 &amp; 9
\end{bmatrix}
\cdot
\begin{bmatrix}
1 \\
0 \\
0
\end{bmatrix} =
\begin{bmatrix}
2 \\
0 \\
0
\end{bmatrix} =
2 \cdot v
\]</span></p>
<p>That’s the beautiful relationship yes? To prove this is not the only one vector, which can do this try this vector <span class="math inline">\(\vec{v} = [0\quad 1\quad 2]\)</span> instead of old <span class="math inline">\(v\)</span>. You should get <span class="math inline">\(11\cdot \vec{v}\)</span></p>
<p>This beautiful relationship comes from the notion of eigenvalues and eigenvectors. In this case <span class="math inline">\(2\)</span> and <span class="math inline">\(11\)</span> are eigenvalues of the matrix <span class="math inline">\(A\)</span>.</p>
<p>Let formalize the notion of eigenvalue and eigenvector:</p>
<blockquote class="blockquote">
<p>Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(n\times n\)</span> <strong>square</strong> matrix. If <span class="math inline">\(\lambda\)</span> is a scalar and <span class="math inline">\(v\)</span> is non-zero vector in <span class="math inline">\(\mathbb{R^n}\)</span> such that <span class="math inline">\(Av = \lambda v\)</span> then we say that <span class="math inline">\(\lambda\)</span> is an <em>eigenvalue</em> and <span class="math inline">\(v\)</span> is <em>eigenvector</em></p>
</blockquote>
<p>I believe you are interested in how to find eigenvalues. Consider again our matrix <span class="math inline">\(A\)</span> and follow steps to find eigenvalues. Given that our matrix <span class="math inline">\(A\)</span> is a square matrix, the condition that characterizes an eigenvalue <span class="math inline">\(\lambda\)</span> is the existence of a nonzero vector <span class="math inline">\(v\)</span> such that <span class="math inline">\(Av = \lambda v\)</span>. We can rewrite this equation in the following way:</p>
<p><span class="math display">\[
Av = \lambda v
\\
Av - \lambda v = 0
\\
Av - \lambda I v = 0
\\
(A - \lambda I)v = 0
\]</span></p>
<p>The final form of this equation makes it clear that <span class="math inline">\(v\)</span> is the solution of a square, homogeneous system. To have the nonzero solution(we required it in above definition), then the determinant of the <strong>coefficient matrix</strong> - <span class="math inline">\((A - \lambda I)\)</span> must be zero. This is achieved when the columns of the coefficient matrix are linearly dependent. In other words, to find eigenvalues we have to choose <span class="math inline">\(\lambda\)</span> such that to solve the following equation:</p>
<p><span class="math display">\[
det(A - \lambda I) = 0
\]</span></p>
<p>This equation is called <strong>characteristic equation</strong></p>
<p>For more clarity, let solve it with a particular example. We have square matrix <span class="math inline">\(A\)</span> and follow the above equation gives us:</p>
<p><span class="math display">\[
det(A - \lambda I) = det\Bigg(
\begin{bmatrix}
2 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 4 \\
0 &amp; 4 &amp; 9
\end{bmatrix} -
\lambda \cdot
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}
\Bigg) =
det\Bigg(
\begin{bmatrix}
2 - \lambda &amp; 0 &amp; 0 \\
0 &amp; 3 - \lambda &amp; 4 \\
0 &amp; 4 &amp; 9 - \lambda
\end{bmatrix}
\Bigg)
\Rightarrow
\\ \quad
\\
\Rightarrow
(2 - \lambda)[(3 - \lambda)(9 - \lambda) - 16] =
-\lambda^3 + 14\lambda^2 - 35\lambda + 22
\]</span></p>
<p>The equation <span class="math inline">\(-\lambda^3 + 14\lambda^2 - 35\lambda + 22\)</span> is called <strong>characteristic polynomial</strong> of the matrix <span class="math inline">\(A\)</span> and will be of degree <span class="math inline">\(n\)</span> if <span class="math inline">\(A\)</span> is <span class="math inline">\(n\times n\)</span></p>
<p>The zeros or roots of this characteristic polynomial are the eigenvalues of the original matrix <span class="math inline">\(A\)</span>. In this case the roots are <span class="math inline">\(2\)</span>, <span class="math inline">\(1\)</span>, and <span class="math inline">\(11\)</span>. Surprise! Our matrix <span class="math inline">\(A\)</span> have three eigenvalues and two of them are already known for us from above example.</p>
<p>Eigenvalues of a square matrix <span class="math inline">\(A\)</span> have some nice features:</p>
<ul>
<li><p>The determinant of <span class="math inline">\(A\)</span> equals to the product of the eigenvalues</p></li>
<li><p>The trace of <span class="math inline">\(A\)</span> (The sum of the elements on the principal diagonal) equal the sum of the eigenvalues</p></li>
<li><p>If <span class="math inline">\(A\)</span> is symmetric matrix, then all of its eigenvalues are real</p></li>
<li><p>If <span class="math inline">\(A\)</span> is invertible (The determinant of <span class="math inline">\(A\)</span> is not zero) and <span class="math inline">\(\lambda_{1}, \cdots, \lambda_{n}\)</span> are its eigenvalues, then the eigenvalues of <span class="math inline">\(A^{-1}\)</span> are <span class="math inline">\(1 / \lambda_{1}, \cdots, 1 / \lambda_{n}\)</span></p></li>
</ul>
<p>From first feature we have that the matrix is invertible if and only if all its eigenvalues are nonzero.</p>
</section>
<section id="eigenvectors" class="level3">
<h3 class="anchored" data-anchor-id="eigenvectors">Eigenvectors</h3>
<p>It’s time to calculate eigenvectors, but let firstly define what is eigenvector and how it relates to the eigenvalue.</p>
<blockquote class="blockquote">
<p>Any nonzero vector <span class="math inline">\(v\)</span> which satisfies characteristic equation is said to be an eigenvector of <span class="math inline">\(A\)</span> corresponding to <span class="math inline">\(\lambda\)</span></p>
</blockquote>
<p>Continue above example and see what are eigenvectors corresponding to eigenvalues <span class="math inline">\(\lambda = 2\)</span>, <span class="math inline">\(\lambda = 1\)</span>, and <span class="math inline">\(\lambda = 11\)</span>, respectively.</p>
<p>Eigenvector for <span class="math inline">\(\lambda = 1\)</span></p>
<p><span class="math display">\[
(A - 1I)\cdot
\begin{bmatrix}
v_{1} \\
v_{2} \\
v_{3}
\end{bmatrix} =\Bigg(
\begin{bmatrix}
2 &amp; 0 &amp; 0 \\
0 &amp; 3 &amp; 4 \\
0 &amp; 4 &amp; 9
\end{bmatrix} -
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1
\end{bmatrix}\Bigg)\cdot
\begin{bmatrix}
v_{1} \\
v_{2} \\
v_{3}
\end{bmatrix} =
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 2 &amp; 4 \\
0 &amp; 4 &amp; 8
\end{bmatrix}\cdot
\begin{bmatrix}
v_{1} \\
v_{2} \\
v_{3}
\end{bmatrix}=
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
\]</span></p>
<p>Rewrite this as a system of equations, we’ll get</p>
<p><span class="math display">\[
\begin{cases}
v_{1} = 0\\
2v_{2} + 4v_{3} = 0\\
4v_{2} + 8v{3} = 0
\end{cases}\rightarrow
\begin{cases}
v_{1} = 0 \\
v_{2} = -2v_{3}\\
v_{3} = 1
\end{cases}
\rightarrow
\begin{cases}
v_{1} = 0 \\
v_{2} = -2\\
v_{3} = 1
\end{cases}
\]</span></p>
<p>So, our eigenvector corresponding to eigenvalue <span class="math inline">\(\lambda = 1\)</span> is</p>
<p><span class="math display">\[
v_{\lambda = 1} =
\begin{bmatrix}
0 \\
-2 \\
1
\end{bmatrix}
\]</span></p>
<p>Finding eigenvectors for <span class="math inline">\(\lambda = 2\)</span> and <span class="math inline">\(\lambda = 11\)</span> is up to you.</p>
</section>
<section id="spectrum-and-spectral-radius" class="level3">
<h3 class="anchored" data-anchor-id="spectrum-and-spectral-radius">Spectrum and Spectral Radius</h3>
<p>The <strong>Spectral Radius</strong> of a square matrix <span class="math inline">\(A\)</span> is the largest absolute values of its eigenvalues and is denoted by <span class="math inline">\(\rho(A)\)</span>. More formally,</p>
<blockquote class="blockquote">
<p>Spectral radius of a <span class="math inline">\(n \times n\)</span> matrix <span class="math inline">\(A\)</span> is:</p>
</blockquote>
<p><span class="math display">\[
\rho(A) = max
\Big\{
\mid \lambda
\mid \ :
\lambda \ is \ an \ eigenvalue \ of \ A
\Big\}
\]</span></p>
<p>Stated otherwise, we have</p>
<p><span class="math display">\[
\rho(A) = max
\Big\{
\mid \lambda_{1}
\mid,
\cdots,
\mid \lambda_{n}
\mid
\Big\}
\]</span></p>
<p>It’s noteworthy that the set of all eigenvalues</p>
<p><span class="math display">\[
\Big\{ \lambda : \lambda \in \lambda(A)
\Big\}
\]</span></p>
<p>is called the <strong>Spectrum</strong></p>
<p>From above example we had three eigenvalues, <span class="math inline">\(\lambda = 2\)</span>, <span class="math inline">\(\lambda = 1\)</span> and <span class="math inline">\(\lambda = 11\)</span> which are spectrum of <span class="math inline">\(A\)</span> and spectral radius for our matrix <span class="math inline">\(A\)</span> is <span class="math inline">\(\lambda = 11\)</span></p>
</section>
</section>
<section id="numerical-representation" class="level2">
<h2 class="anchored" data-anchor-id="numerical-representation">Numerical Representation</h2>
<section id="kernel-or-null-space-of-a-matrix" class="level3">
<h3 class="anchored" data-anchor-id="kernel-or-null-space-of-a-matrix">Kernel or Null Space of a Matrix</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.linalg <span class="im">import</span> null_space</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">2</span>,<span class="dv">7</span>,<span class="dv">1</span>,<span class="dv">3</span>], [<span class="op">-</span><span class="dv">4</span>,<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>], [<span class="op">-</span><span class="dv">1</span>,<span class="dv">7</span>,<span class="dv">3</span>,<span class="dv">2</span>],[<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">0</span>]])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>kernel_A <span class="op">=</span> null_space(A)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Normalized Kernel"</span>, kernel_A, sep<span class="op">=</span><span class="st">'</span><span class="ch">\n</span><span class="st">'</span>) <span class="co"># This matrix is normalized, meaning that it has unit length</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># To find unnormalized kernel we have to do the following:</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Import sympy</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sympy <span class="im">import</span> Matrix</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> [[<span class="dv">2</span>,<span class="dv">7</span>,<span class="dv">1</span>,<span class="dv">3</span>], [<span class="op">-</span><span class="dv">4</span>,<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="op">-</span><span class="dv">2</span>], [<span class="op">-</span><span class="dv">1</span>,<span class="dv">7</span>,<span class="dv">3</span>,<span class="dv">2</span>],[<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">0</span>]]</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> Matrix(B)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>kernel_B <span class="op">=</span> B.nullspace()</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Unnormalized Kernel"</span>, kernel_B, sep<span class="op">=</span><span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># In unnormilized case, we clearly see that sympy automatically choose values for our free variables. </span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># In first case x_3 = 1; x_4 = 0 and in the second case x_3 = 0; x_4 = 1</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Resulted vector(s) are basis for the null space for our matrix A</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Normalized Kernel
[[ 0.59408621  0.00166   ]
 [-0.09787364 -0.40852336]
 [ 0.69195985  0.41018336]
 [-0.39833892  0.81538673]]

Unnormalized Kernel
[Matrix([
[ 2/3],
[-1/3],
[   1],
[   0]]), Matrix([
[-1/3],
[-1/3],
[   0],
[   1]])]</code></pre>
</section>
<section id="linear-transformations" class="level3">
<h3 class="anchored" data-anchor-id="linear-transformations">Linear Transformations</h3>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">0</span>])</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">2</span>,<span class="dv">0</span>],</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">0</span>,<span class="dv">2</span>]])</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> A<span class="op">@</span>v <span class="co"># dot product</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"Resulted vector is: t ="</span>, t)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot v and t</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>vecs <span class="op">=</span> np.array([t,v])</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>origin <span class="op">=</span> [<span class="dv">0</span>], [<span class="dv">0</span>]</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>plt.quiver(<span class="op">*</span>origin, vecs[:,<span class="dv">0</span>], vecs[:,<span class="dv">1</span>], color<span class="op">=</span>[<span class="st">'blue'</span>, <span class="st">'green'</span>], scale<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Original vector v is green and transformed vector t is blue.</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Vector t has same direction as v but greater magnitude</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Resulted vector is: t = [2 0]</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="{static}../../images/Linear_Algebra_Advance_Part_I_figure2_1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">picture</figcaption><p></p>
</figure>
</div>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">0</span>])</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">1</span>,<span class="dv">0</span>]])</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> A<span class="op">@</span>v</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"Resulted vector is: t ="</span>, t)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot v and t</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>vecs <span class="op">=</span> np.array([v,t])</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>origin <span class="op">=</span> [<span class="dv">0</span>], [<span class="dv">0</span>]</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>plt.quiver(<span class="op">*</span>origin, vecs[:,<span class="dv">0</span>], vecs[:,<span class="dv">1</span>], color<span class="op">=</span>[<span class="st">'green'</span>, <span class="st">'blue'</span>], scale<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Resulted vector change the direction but has the same length</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Resulted vector is: t = [0 1]</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="{static}../../images/Linear_Algebra_Advance_Part_I_figure3_1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">picture</figcaption><p></p>
</figure>
</div>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">0</span>])</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">2</span>,<span class="dv">1</span>],</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">1</span>,<span class="dv">2</span>]])</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> A<span class="op">@</span>v</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"Resulted vector is: t ="</span>, t)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot v and t</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>vecs <span class="op">=</span> np.array([v,t])</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>origin <span class="op">=</span> [<span class="dv">0</span>], [<span class="dv">0</span>]</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>plt.quiver(<span class="op">*</span>origin, vecs[:,<span class="dv">0</span>], vecs[:,<span class="dv">1</span>], color<span class="op">=</span>[<span class="st">'green'</span>, <span class="st">'blue'</span>], scale<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Resulted vector changed the direction, as well as the length</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Resulted vector is: t = [2 1]</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="{static}../../images/Linear_Algebra_Advance_Part_I_figure4_1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">picture</figcaption><p></p>
</figure>
</div>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">1</span>])</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">5</span>,<span class="dv">2</span>],</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">3</span>,<span class="dv">1</span>]])</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.array([<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">6</span>])</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> A<span class="op">@</span>v <span class="op">+</span> b</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"Resulted vector is: t ="</span>, t)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot v and t</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>vecs <span class="op">=</span> np.array([v,t])</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>origin <span class="op">=</span> [<span class="dv">0</span>], [<span class="dv">0</span>]</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.quiver(<span class="op">*</span>origin, vecs[:,<span class="dv">0</span>], vecs[:,<span class="dv">1</span>], color<span class="op">=</span>[<span class="st">'green'</span>, <span class="st">'blue'</span>], scale<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="co"># The resulted vector t is blue</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Resulted vector is: t = [ 5 -2]</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="{static}../../images/Linear_Algebra_Advance_Part_I_figure5_1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">picture</figcaption><p></p>
</figure>
</div>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3">
<h3 class="anchored" data-anchor-id="eigenvalues-and-eigenvectors">Eigenvalues and Eigenvectors</h3>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>],</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">0</span>,<span class="dv">3</span>,<span class="dv">4</span>],</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">9</span>]])</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>eigenvalues, eigenvectors <span class="op">=</span> np.linalg.eig(A)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Eigenvalues are: "</span>, eigenvalues)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Eigenvectors are: "</span>, eigenvectors, sep<span class="op">=</span><span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that this eigenvectors seems different from my calculation. However they are not different.</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co"># They are normalized to have unit length</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Eigenvalues are:  [11.  1.  2.]

Eigenvectors are:
[[ 0.          0.          1.        ]
 [ 0.4472136   0.89442719  0.        ]
 [ 0.89442719 -0.4472136   0.        ]]</code></pre>
</section>
</section>
<section id="conclusion-for-part-i" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-for-part-i">Conclusion for part I</h2>
<p>In conclusion, part one is relatively heavy but as it contains lots of calculations. That’s why we use computers to solve this kind of problems. Despite Numpy’s build in functions there is big avenue to write algorithm to compute eigenvalues for instance. That would be very helpful for practicing linear algebra and python simultaneously.</p>
<p>The second part is devoted solely for matrix decompositions.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p><a href="http://linear.axler.net/">Linear Algebra Done Right</a></p>
<p><a href="https://en.wikipedia.org/wiki/List_of_linear_algebra_topics">Linear Algebra Topics</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">Copyright 2023, Nodar Okroshiashvili</div>
  </div>
</footer>



</body></html>